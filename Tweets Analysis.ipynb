{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b0b4f1f5",
   "metadata": {},
   "source": [
    "### Project Overview\n",
    "In this project, we apply NLP techniques to classify tweets into disaster and non-disaster categories. Given the ubiquity of social media, platforms like Twitter have become invaluable for real-time information sharing during emergencies and natural disasters. \n",
    "\n",
    "However, the vast amount of data generated on these platforms necessitates automated systems to quickly and accurately sift through tweets to identify those that are genuinely related to disasters. This capability can significantly aid emergency response teams and disaster relief operations by providing them with timely and relevant information, potentially saving lives and resources.\n",
    "\n",
    "To address this challenge, we leverage various NLP techniques and machine learning models. The project involves data exploration to understand the characteristics of the dataset, preprocessing steps to clean and prepare the text data, and the application of GloVe embeddings to capture semantic meanings of words effectively. The core of our approach is building a predictive model using Long Short-Term Memory (LSTM) networks, a type of Recurrent Neural Network (RNN) that is particularly suited for sequential data like text.\n",
    "\n",
    "**Natural Language Processing(NLP):**\n",
    "Natural Language Processing (NLP) is a field at the intersection of computer science, artificial intelligence, and linguistics. It focuses on the interaction between computers and humans through natural language. The ultimate objective of NLP is to enable computers to understand, interpret, and generate human languages in a way that is both valuable and meaningful. This involves a range of tasks such as speech recognition, natural language understanding, natural language generation, and sentiment analysis, among others."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3a4b0129",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_19494/4166994926.py:1: DeprecationWarning: \n",
      "Pyarrow will become a required dependency of pandas in the next major release of pandas (pandas 3.0),\n",
      "(to allow more performant data types, such as the Arrow string type, and better interoperability with other libraries)\n",
      "but was not found to be installed on your system.\n",
      "If this would cause problems for you,\n",
      "please provide us feedback at https://github.com/pandas-dev/pandas/issues/54466\n",
      "        \n",
      "  import pandas as pd\n",
      "2024-02-17 17:44:23.887620: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-02-17 17:44:23.887668: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-02-17 17:44:23.888386: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-02-17 17:44:23.893102: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-02-17 17:44:24.593360: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer,CountVectorizer\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import f1_score,accuracy_score,roc_auc_score\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Dense, Bidirectional,Dropout\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5e4e8fc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df=pd.read_csv(os.getcwd()+\"/nlp-getting-started/train.csv\")\n",
    "test_df=pd.read_csv(os.getcwd()+\"/nlp-getting-started/test.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19745e19-56bf-420f-aa52-85c166987dc8",
   "metadata": {},
   "source": [
    "### Training Data Exploration \n",
    "To explore the data we displayed the training dataset. We can see from the data below that we have text and their target in the data frame. Here is the list of attributes in the training data\n",
    "1. id\n",
    "2. Keyword\n",
    "3. location\n",
    "4. text\n",
    "5. Traget\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "162d1047",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>keyword</th>\n",
       "      <th>location</th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Our Deeds are the Reason of this #earthquake M...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Forest fire near La Ronge Sask. Canada</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>All residents asked to 'shelter in place' are ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13,000 people receive #wildfires evacuation or...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Just got sent this photo from Ruby #Alaska as ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id keyword location                                               text  \\\n",
       "0   1     NaN      NaN  Our Deeds are the Reason of this #earthquake M...   \n",
       "1   4     NaN      NaN             Forest fire near La Ronge Sask. Canada   \n",
       "2   5     NaN      NaN  All residents asked to 'shelter in place' are ...   \n",
       "3   6     NaN      NaN  13,000 people receive #wildfires evacuation or...   \n",
       "4   7     NaN      NaN  Just got sent this photo from Ruby #Alaska as ...   \n",
       "\n",
       "   target  \n",
       "0       1  \n",
       "1       1  \n",
       "2       1  \n",
       "3       1  \n",
       "4       1  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9595eae3-eef4-49bb-a0e9-01d6680f153a",
   "metadata": {},
   "source": [
    "### Test Data Exploration \n",
    "To explore the test data we displayed the training dataset. We can see from the data below that we all feature as the training data frame except for the target feature. Here is the list of attributes in the test data \n",
    "1. id\n",
    "2. Keyword\n",
    "3. location\n",
    "4. text\n",
    "   \n",
    "So our task is to predict these labels for the tweets in test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c9e52248",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>keyword</th>\n",
       "      <th>location</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Just happened a terrible car crash</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Heard about #earthquake is different cities, s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>there is a forest fire at spot pond, geese are...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Apocalypse lighting. #Spokane #wildfires</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Typhoon Soudelor kills 28 in China and Taiwan</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id keyword location                                               text\n",
       "0   0     NaN      NaN                 Just happened a terrible car crash\n",
       "1   2     NaN      NaN  Heard about #earthquake is different cities, s...\n",
       "2   3     NaN      NaN  there is a forest fire at spot pond, geese are...\n",
       "3   9     NaN      NaN           Apocalypse lighting. #Spokane #wildfires\n",
       "4  11     NaN      NaN      Typhoon Soudelor kills 28 in China and Taiwan"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42054542-4b9a-4951-8002-4ed5966d3141",
   "metadata": {},
   "source": [
    "### Train/Test Data Distribution \n",
    "Let's take a moment to examine the sizes of our training and test datasets. The training data consists of a total of 7613 tweets, while the test data comprises 3263 tweets. This information provides an overview of the quantity of data available for both training our model and evaluating its performance on unseen test samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4ff3dab2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7613, 5)\n",
      "(3263, 4)\n"
     ]
    }
   ],
   "source": [
    "print(train_df.shape)\n",
    "print(test_df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58cb4241-5941-4519-a6ea-54a6e6771241",
   "metadata": {},
   "source": [
    "### Class Distribution\n",
    "Let's take a closer look at how the different classes are spread out in our training data. From the bar chart, it's clear that out of around 7600 tweets, roughly 4300 belong to class 0, and about 3300 are in class 1. While the classes aren't perfectly balanced, with more tweets in class 0, it's still good enough for doing classification without needing to tweak the distribution. In simpler terms, we can effectively work with the data as it is without making any adjustments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cbc42921",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#class distribution\n",
    "counts = train_df[\"target\"].value_counts()\n",
    "plt.bar(counts.index, counts.values,color='green')\n",
    "plt.ylabel(\"Category Count\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "689a36c2-8c85-417d-a742-0226f96f9b5e",
   "metadata": {},
   "source": [
    "### Missing value detection and removal \n",
    "Let's analyze the presence of missing values in both the training and test datasets. In the training data, we observe that there are no missing values in the 'id,' 'text,' and 'target' columns. However, the 'keyword' column has 61 missing values, and the 'location' column has 2533 missing values.\n",
    "\n",
    "Moving on to the test data, we find a similar pattern of no missing values in the 'id,' 'text,' and 'keyword' columns. However, the 'location' column in the test data has 1105 missing value\n",
    "\n",
    "To fix the missing information in both the training and test datasets, we've decided to replace the empty spots with nothing. This way, we keep the data complete and tidy for further analysis and model training.\n",
    "\n",
    "In the training data, we're filling in the missing values in the 'keyword' and 'location' columns with empty spaces. Similarly, in the test data, we're putting empty spaces in place of missing values in the 'location' column.\n",
    "\n",
    "This straightforward approach helps maintain the datasets in good shape for future steps, making sure the missing values don't cause any issues as we move forward with our analysis and machine learning model train\n",
    "ing.s."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "46ee8f61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values in training data\n",
      "id             0\n",
      "keyword       61\n",
      "location    2533\n",
      "text           0\n",
      "target         0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(\"Missing values in training data\")\n",
    "missing_count_tr=train_df.isnull().sum()\n",
    "print(missing_count_tr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9025092e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values in test data\n",
      "id             0\n",
      "keyword       26\n",
      "location    1105\n",
      "text           0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(\"Missing values in test data\")\n",
    "missing_count_ts=test_df.isnull().sum()\n",
    "print(missing_count_ts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5ae6cc9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.fillna('', inplace=True)\n",
    "test_df.fillna('', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ed8a6ce6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>keyword</th>\n",
       "      <th>location</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Just happened a terrible car crash</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Heard about #earthquake is different cities, s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>there is a forest fire at spot pond, geese are...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Apocalypse lighting. #Spokane #wildfires</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Typhoon Soudelor kills 28 in China and Taiwan</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id keyword location                                               text\n",
       "0   0                                  Just happened a terrible car crash\n",
       "1   2                   Heard about #earthquake is different cities, s...\n",
       "2   3                   there is a forest fire at spot pond, geese are...\n",
       "3   9                            Apocalypse lighting. #Spokane #wildfires\n",
       "4  11                       Typhoon Soudelor kills 28 in China and Taiwan"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "45d88f98",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>keyword</th>\n",
       "      <th>location</th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Our Deeds are the Reason of this #earthquake M...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Forest fire near La Ronge Sask. Canada</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>All residents asked to 'shelter in place' are ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>13,000 people receive #wildfires evacuation or...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Just got sent this photo from Ruby #Alaska as ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id keyword location                                               text  \\\n",
       "0   1                   Our Deeds are the Reason of this #earthquake M...   \n",
       "1   4                              Forest fire near La Ronge Sask. Canada   \n",
       "2   5                   All residents asked to 'shelter in place' are ...   \n",
       "3   6                   13,000 people receive #wildfires evacuation or...   \n",
       "4   7                   Just got sent this photo from Ruby #Alaska as ...   \n",
       "\n",
       "   target  \n",
       "0       1  \n",
       "1       1  \n",
       "2       1  \n",
       "3       1  \n",
       "4       1  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "171ce4b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df[\"tweet-length\"] = train_df[\"text\"].map(len)\n",
    "test_df[\"tweet-length\"] = test_df[\"text\"].map(len)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fc5d848-e2b0-42ab-b1a8-ed4456dd6fa8",
   "metadata": {},
   "source": [
    "### Tweet Length Analysis\n",
    "In both the test and training data, we checked the lengths of tweets. In the training data:\n",
    "\n",
    "1. The shortest tweet has 7 characters.\n",
    "2. The longest tweet has 157 characters.\n",
    "3. On average, tweets are about 101 characters long.\n",
    "\n",
    "In test data\n",
    "1. The shortest tweet has 5 characters.\n",
    "2. The longest tweet has 151 characters.\n",
    "3. On average, tweets are about 102 characters long.\n",
    "\n",
    "So, tweets in both the training and test datasets are about the same length on average, around 101 characters. So, they're pretty similar in terms of tweet length.odata."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "28cbdae0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>target</th>\n",
       "      <th>tweet-length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>7613.000000</td>\n",
       "      <td>7613.00000</td>\n",
       "      <td>7613.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>5441.934848</td>\n",
       "      <td>0.42966</td>\n",
       "      <td>101.037436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>3137.116090</td>\n",
       "      <td>0.49506</td>\n",
       "      <td>33.781325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>7.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>2734.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>78.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>5408.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>107.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>8146.000000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>133.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>10873.000000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>157.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id      target  tweet-length\n",
       "count   7613.000000  7613.00000   7613.000000\n",
       "mean    5441.934848     0.42966    101.037436\n",
       "std     3137.116090     0.49506     33.781325\n",
       "min        1.000000     0.00000      7.000000\n",
       "25%     2734.000000     0.00000     78.000000\n",
       "50%     5408.000000     0.00000    107.000000\n",
       "75%     8146.000000     1.00000    133.000000\n",
       "max    10873.000000     1.00000    157.000000"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c07a193",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5280011b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>tweet-length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>3263.000000</td>\n",
       "      <td>3263.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>5427.152927</td>\n",
       "      <td>102.108183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>3146.427221</td>\n",
       "      <td>33.972158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>2683.000000</td>\n",
       "      <td>78.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>5500.000000</td>\n",
       "      <td>109.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>8176.000000</td>\n",
       "      <td>134.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>10875.000000</td>\n",
       "      <td>151.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id  tweet-length\n",
       "count   3263.000000   3263.000000\n",
       "mean    5427.152927    102.108183\n",
       "std     3146.427221     33.972158\n",
       "min        0.000000      5.000000\n",
       "25%     2683.000000     78.000000\n",
       "50%     5500.000000    109.000000\n",
       "75%     8176.000000    134.000000\n",
       "max    10875.000000    151.000000"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "673b5a26",
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets = train_df[\"text\"].values\n",
    "targets = train_df[\"target\"].values\n",
    "test_tweets = test_df[\"text\"].values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db107e9a-1eed-41d3-8faa-440554f7f95d",
   "metadata": {},
   "source": [
    "### Data Cleaning\n",
    "It is important to clean data before applying an embedding technique to it. The following steps were performed to clean the data:\n",
    "\n",
    "1. Tokenization is like breaking down a sentence into smaller pieces, like words or parts of words. We extracted the tokens from each of the tweets.\n",
    "\n",
    "2. All characters in the text were converted to lowercase. This ensures that the same words with different cases are not treated differently.\n",
    "\n",
    "3. Stop words were removed to make sure that they do not contribute to the model.\n",
    "\n",
    "ed tasks.\n",
    "ta smarter way.ataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45e272cc-156b-4c64-9b17-13f6df0ee992",
   "metadata": {},
   "source": [
    "### Word Embedding\n",
    "\n",
    "GloVe embeddings are word representations that understand the meaning of words based on how they appear together in sentences. We're using GloVe embedding on the tweets for the following reasons:\n",
    "\n",
    "1. GloVe helps models understand words and their meanings, making them better at tasks like understanding sentiments in tweets.\n",
    "\n",
    "2. These models are pre-trained on very large datasets of words. So they are reliable and ready to use.\n",
    "\n",
    "3. GloVe embeddings are used for lots of positive or negative classifications of text-based data.\n",
    "\n",
    "4. Adding GloVe to models makes them smarter. They can guess the relationships between words.\n",
    "\n",
    "In summary, GloVe embeddings improve language understanding in models, making them more effective for various text-based tasks.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6428b998",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "import numpy as np\n",
    "\n",
    "max_words = 5000  \n",
    "tokenizer = Tokenizer(num_words=max_words)\n",
    "tokenizer.fit_on_texts(tweets)\n",
    "sequences_train = tokenizer.texts_to_sequences(tweets)\n",
    "sequences_test = tokenizer.texts_to_sequences(test_tweets)\n",
    "\n",
    "max_sequence_length_train = max(len(seq) for seq in sequences_train)\n",
    "max_sequence_length_test = max(len(seq) for seq in sequences_test)\n",
    "max_sequence_length = max(max_sequence_length_train, max_sequence_length_test)\n",
    "\n",
    "\n",
    "padded_sequences_train = pad_sequences(sequences_train, maxlen=max_sequence_length)\n",
    "padded_sequences_test = pad_sequences(sequences_test, maxlen=max_sequence_length)\n",
    "\n",
    "\\\n",
    "embedding_dim = 100 \n",
    "embedding_index = {}\n",
    "glove_file_path = os.getcwd()+\"/glove.6B.100d.txt\"  \n",
    "\n",
    "with open(glove_file_path, encoding='utf-8') as f:\n",
    "    for line in f:\n",
    "        values = line.split()\n",
    "        word = values[0]\n",
    "        coefs = np.asarray(values[1:], dtype='float32')\n",
    "        embedding_index[word] = coefs\n",
    "\n",
    "\n",
    "embedding_matrix = np.zeros((max_words, embedding_dim))\n",
    "for word, i in tokenizer.word_index.items():\n",
    "    if i < max_words:\n",
    "        embedding_vector = embedding_index.get(word)\n",
    "        if embedding_vector is not None:\n",
    "            embedding_matrix[i] = embedding_vector\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5247ba04-f688-46f2-9d21-2544a8738c21",
   "metadata": {},
   "source": [
    "### Model\n",
    "We created a model for understanding and predicting whether a piece of text is related to a particular topic or not. The model has three main parts:\n",
    "\n",
    "Embedding Layer: This part helps the model understand the meaning of words in our text. It takes the words in our data and turns them into numbers, making it easier for the computer to work with them.\n",
    "\n",
    "LSTM Layer: This part of the model learns patterns and relationships in the data. It's like the brain of the model that remembers important things from the past while processing new information.\n",
    "\n",
    "Dense Layer: This is the output layer that makes the final prediction. It tells us if the text is related to the topic or not.\n",
    "\n",
    "We used the Adam optimizer, a special algorithm that helps the model learn better from the data, and we set a learning rate to control how fast the model learns.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ba4919dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-17 17:44:31.762266: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-02-17 17:44:31.783367: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-02-17 17:44:31.783421: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-02-17 17:44:31.787650: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-02-17 17:44:31.787846: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-02-17 17:44:31.787904: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-02-17 17:44:31.943275: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-02-17 17:44:31.943426: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-02-17 17:44:31.943437: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2022] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "2024-02-17 17:44:31.943486: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-02-17 17:44:31.943504: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1929] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 2242 MB memory:  -> device: 0, name: NVIDIA GeForce GTX 1650 Ti, pci bus id: 0000:01:00.0, compute capability: 7.5\n",
      "2024-02-17 17:44:32.174302: I external/local_tsl/tsl/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-17 17:44:33.664105: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:454] Loaded cuDNN version 8904\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  1/952 [..............................] - ETA: 26:35 - loss: 0.7748 - accuracy: 0.3750"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-17 17:44:33.988344: I external/local_xla/xla/service/service.cc:168] XLA service 0x7fc22c508450 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2024-02-17 17:44:33.988383: I external/local_xla/xla/service/service.cc:176]   StreamExecutor device (0): NVIDIA GeForce GTX 1650 Ti, Compute Capability 7.5\n",
      "2024-02-17 17:44:33.994442: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1708173874.069894   19567 device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "952/952 [==============================] - 9s 8ms/step - loss: 0.5141 - accuracy: 0.7532\n",
      "Epoch 2/100\n",
      "952/952 [==============================] - 9s 10ms/step - loss: 0.4387 - accuracy: 0.8030\n",
      "Epoch 3/100\n",
      "952/952 [==============================] - 9s 10ms/step - loss: 0.4201 - accuracy: 0.8187\n",
      "Epoch 4/100\n",
      "952/952 [==============================] - 9s 10ms/step - loss: 0.4089 - accuracy: 0.8223\n",
      "Epoch 5/100\n",
      "952/952 [==============================] - 9s 10ms/step - loss: 0.3977 - accuracy: 0.8306\n",
      "Epoch 6/100\n",
      "952/952 [==============================] - 10s 10ms/step - loss: 0.3901 - accuracy: 0.8349\n",
      "Epoch 7/100\n",
      "952/952 [==============================] - 9s 10ms/step - loss: 0.3817 - accuracy: 0.8355\n",
      "Epoch 8/100\n",
      "952/952 [==============================] - 9s 9ms/step - loss: 0.3751 - accuracy: 0.8384\n",
      "Epoch 9/100\n",
      "952/952 [==============================] - 9s 9ms/step - loss: 0.3674 - accuracy: 0.8441\n",
      "Epoch 10/100\n",
      "952/952 [==============================] - 9s 9ms/step - loss: 0.3627 - accuracy: 0.8474\n",
      "Epoch 11/100\n",
      "952/952 [==============================] - 9s 9ms/step - loss: 0.3553 - accuracy: 0.8488\n",
      "Epoch 12/100\n",
      "952/952 [==============================] - 9s 9ms/step - loss: 0.3513 - accuracy: 0.8507\n",
      "Epoch 13/100\n",
      "952/952 [==============================] - 9s 9ms/step - loss: 0.3444 - accuracy: 0.8575\n",
      "Epoch 14/100\n",
      "952/952 [==============================] - 9s 9ms/step - loss: 0.3377 - accuracy: 0.8630\n",
      "Epoch 15/100\n",
      "952/952 [==============================] - 9s 9ms/step - loss: 0.3327 - accuracy: 0.8601\n",
      "Epoch 16/100\n",
      "952/952 [==============================] - 9s 9ms/step - loss: 0.3264 - accuracy: 0.8652\n",
      "Epoch 17/100\n",
      "952/952 [==============================] - 9s 9ms/step - loss: 0.3226 - accuracy: 0.8688\n",
      "Epoch 18/100\n",
      "952/952 [==============================] - 9s 9ms/step - loss: 0.3171 - accuracy: 0.8690\n",
      "Epoch 19/100\n",
      "952/952 [==============================] - 9s 9ms/step - loss: 0.3116 - accuracy: 0.8698\n",
      "Epoch 20/100\n",
      "952/952 [==============================] - 9s 10ms/step - loss: 0.3080 - accuracy: 0.8756\n",
      "Epoch 21/100\n",
      "952/952 [==============================] - 10s 10ms/step - loss: 0.3017 - accuracy: 0.8776\n",
      "Epoch 22/100\n",
      "952/952 [==============================] - 9s 9ms/step - loss: 0.2977 - accuracy: 0.8818\n",
      "Epoch 23/100\n",
      "952/952 [==============================] - 9s 9ms/step - loss: 0.2917 - accuracy: 0.8835\n",
      "Epoch 24/100\n",
      "952/952 [==============================] - 9s 9ms/step - loss: 0.2884 - accuracy: 0.8836\n",
      "Epoch 25/100\n",
      "952/952 [==============================] - 9s 9ms/step - loss: 0.2839 - accuracy: 0.8861\n",
      "Epoch 26/100\n",
      "952/952 [==============================] - 9s 9ms/step - loss: 0.2786 - accuracy: 0.8910\n",
      "Epoch 27/100\n",
      "952/952 [==============================] - 9s 9ms/step - loss: 0.2762 - accuracy: 0.8874\n",
      "Epoch 28/100\n",
      "952/952 [==============================] - 9s 9ms/step - loss: 0.2710 - accuracy: 0.8944\n",
      "Epoch 29/100\n",
      "952/952 [==============================] - 9s 9ms/step - loss: 0.2672 - accuracy: 0.8933\n",
      "Epoch 30/100\n",
      "952/952 [==============================] - 9s 9ms/step - loss: 0.2623 - accuracy: 0.8966\n",
      "Epoch 31/100\n",
      "952/952 [==============================] - 9s 9ms/step - loss: 0.2573 - accuracy: 0.8994\n",
      "Epoch 32/100\n",
      "952/952 [==============================] - 9s 9ms/step - loss: 0.2549 - accuracy: 0.9014\n",
      "Epoch 33/100\n",
      "952/952 [==============================] - 9s 9ms/step - loss: 0.2507 - accuracy: 0.9053\n",
      "Epoch 34/100\n",
      "952/952 [==============================] - 9s 9ms/step - loss: 0.2483 - accuracy: 0.9058\n",
      "Epoch 35/100\n",
      "952/952 [==============================] - 9s 9ms/step - loss: 0.2463 - accuracy: 0.9053\n",
      "Epoch 36/100\n",
      "952/952 [==============================] - 9s 9ms/step - loss: 0.2422 - accuracy: 0.9086\n",
      "Epoch 37/100\n",
      "952/952 [==============================] - 9s 9ms/step - loss: 0.2379 - accuracy: 0.9098\n",
      "Epoch 38/100\n",
      "952/952 [==============================] - 9s 10ms/step - loss: 0.2327 - accuracy: 0.9100\n",
      "Epoch 39/100\n",
      "952/952 [==============================] - 9s 9ms/step - loss: 0.2293 - accuracy: 0.9108\n",
      "Epoch 40/100\n",
      "952/952 [==============================] - 9s 9ms/step - loss: 0.2366 - accuracy: 0.9073\n",
      "Epoch 41/100\n",
      "952/952 [==============================] - 9s 9ms/step - loss: 0.2244 - accuracy: 0.9146\n",
      "Epoch 42/100\n",
      "952/952 [==============================] - 9s 9ms/step - loss: 0.2249 - accuracy: 0.9144\n",
      "Epoch 43/100\n",
      "952/952 [==============================] - 9s 9ms/step - loss: 0.2220 - accuracy: 0.9132\n",
      "Epoch 44/100\n",
      "952/952 [==============================] - 9s 9ms/step - loss: 0.2160 - accuracy: 0.9171\n",
      "Epoch 45/100\n",
      "952/952 [==============================] - 9s 9ms/step - loss: 0.2213 - accuracy: 0.9133\n",
      "Epoch 46/100\n",
      "952/952 [==============================] - 9s 9ms/step - loss: 0.2119 - accuracy: 0.9207\n",
      "Epoch 47/100\n",
      "952/952 [==============================] - 9s 9ms/step - loss: 0.2093 - accuracy: 0.9200\n",
      "Epoch 48/100\n",
      "952/952 [==============================] - 9s 9ms/step - loss: 0.2049 - accuracy: 0.9211\n",
      "Epoch 49/100\n",
      "952/952 [==============================] - 9s 9ms/step - loss: 0.2040 - accuracy: 0.9237\n",
      "Epoch 50/100\n",
      "952/952 [==============================] - 9s 9ms/step - loss: 0.2014 - accuracy: 0.9220\n",
      "Epoch 51/100\n",
      "952/952 [==============================] - 9s 9ms/step - loss: 0.2002 - accuracy: 0.9253\n",
      "Epoch 52/100\n",
      "952/952 [==============================] - 9s 9ms/step - loss: 0.1982 - accuracy: 0.9258\n",
      "Epoch 53/100\n",
      "952/952 [==============================] - 9s 9ms/step - loss: 0.1939 - accuracy: 0.9293\n",
      "Epoch 54/100\n",
      "952/952 [==============================] - 9s 9ms/step - loss: 0.1981 - accuracy: 0.9272\n",
      "Epoch 55/100\n",
      "952/952 [==============================] - 9s 9ms/step - loss: 0.1915 - accuracy: 0.9304\n",
      "Epoch 56/100\n",
      "952/952 [==============================] - 9s 9ms/step - loss: 0.1873 - accuracy: 0.9316\n",
      "Epoch 57/100\n",
      "952/952 [==============================] - 9s 10ms/step - loss: 0.1889 - accuracy: 0.9301\n",
      "Epoch 58/100\n",
      "952/952 [==============================] - 9s 9ms/step - loss: 0.1791 - accuracy: 0.9366\n",
      "Epoch 59/100\n",
      "952/952 [==============================] - 9s 9ms/step - loss: 0.1884 - accuracy: 0.9306\n",
      "Epoch 60/100\n",
      "952/952 [==============================] - 9s 9ms/step - loss: 0.1780 - accuracy: 0.9368\n",
      "Epoch 61/100\n",
      "952/952 [==============================] - 9s 9ms/step - loss: 0.1767 - accuracy: 0.9400\n",
      "Epoch 62/100\n",
      "952/952 [==============================] - 9s 9ms/step - loss: 0.1766 - accuracy: 0.9388\n",
      "Epoch 63/100\n",
      "952/952 [==============================] - 9s 9ms/step - loss: 0.1690 - accuracy: 0.9391\n",
      "Epoch 64/100\n",
      "952/952 [==============================] - 9s 9ms/step - loss: 0.1745 - accuracy: 0.9381\n",
      "Epoch 65/100\n",
      "952/952 [==============================] - 9s 9ms/step - loss: 0.1690 - accuracy: 0.9391\n",
      "Epoch 66/100\n",
      "952/952 [==============================] - 9s 9ms/step - loss: 0.1669 - accuracy: 0.9408\n",
      "Epoch 67/100\n",
      "952/952 [==============================] - 9s 9ms/step - loss: 0.1648 - accuracy: 0.9418\n",
      "Epoch 68/100\n",
      "952/952 [==============================] - 9s 9ms/step - loss: 0.1754 - accuracy: 0.9377\n",
      "Epoch 69/100\n",
      "952/952 [==============================] - 9s 9ms/step - loss: 0.1665 - accuracy: 0.9417\n",
      "Epoch 70/100\n",
      "952/952 [==============================] - 9s 9ms/step - loss: 0.1571 - accuracy: 0.9451\n",
      "Epoch 71/100\n",
      "952/952 [==============================] - 9s 9ms/step - loss: 0.1620 - accuracy: 0.9438\n",
      "Epoch 72/100\n",
      "952/952 [==============================] - 9s 9ms/step - loss: 0.1565 - accuracy: 0.9465\n",
      "Epoch 73/100\n",
      "952/952 [==============================] - 9s 9ms/step - loss: 0.1606 - accuracy: 0.9426\n",
      "Epoch 74/100\n",
      "952/952 [==============================] - 9s 9ms/step - loss: 0.1532 - accuracy: 0.9468\n",
      "Epoch 75/100\n",
      "952/952 [==============================] - 9s 9ms/step - loss: 0.1627 - accuracy: 0.9439\n",
      "Epoch 76/100\n",
      "952/952 [==============================] - 9s 9ms/step - loss: 0.1502 - accuracy: 0.9461\n",
      "Epoch 77/100\n",
      "952/952 [==============================] - 9s 9ms/step - loss: 0.1525 - accuracy: 0.9455\n",
      "Epoch 78/100\n",
      "952/952 [==============================] - 9s 9ms/step - loss: 0.1495 - accuracy: 0.9488\n",
      "Epoch 79/100\n",
      "952/952 [==============================] - 9s 9ms/step - loss: 0.1467 - accuracy: 0.9514\n",
      "Epoch 80/100\n",
      "952/952 [==============================] - 9s 9ms/step - loss: 0.1540 - accuracy: 0.9455\n",
      "Epoch 81/100\n",
      "952/952 [==============================] - 9s 9ms/step - loss: 0.1458 - accuracy: 0.9482\n",
      "Epoch 82/100\n",
      "952/952 [==============================] - 9s 9ms/step - loss: 0.1438 - accuracy: 0.9498\n",
      "Epoch 83/100\n",
      "952/952 [==============================] - 9s 9ms/step - loss: 0.1421 - accuracy: 0.9518\n",
      "Epoch 84/100\n",
      "952/952 [==============================] - 9s 9ms/step - loss: 0.1415 - accuracy: 0.9518\n",
      "Epoch 85/100\n",
      "952/952 [==============================] - 9s 9ms/step - loss: 0.1398 - accuracy: 0.9514\n",
      "Epoch 86/100\n",
      "952/952 [==============================] - 9s 9ms/step - loss: 0.1359 - accuracy: 0.9522\n",
      "Epoch 87/100\n",
      "952/952 [==============================] - 9s 9ms/step - loss: 0.1349 - accuracy: 0.9546\n",
      "Epoch 88/100\n",
      "952/952 [==============================] - 10s 10ms/step - loss: 0.1410 - accuracy: 0.9515\n",
      "Epoch 89/100\n",
      "952/952 [==============================] - 10s 11ms/step - loss: 0.1343 - accuracy: 0.9526\n",
      "Epoch 90/100\n",
      "952/952 [==============================] - 9s 10ms/step - loss: 0.1322 - accuracy: 0.9553\n",
      "Epoch 91/100\n",
      "952/952 [==============================] - 9s 10ms/step - loss: 0.1325 - accuracy: 0.9536\n",
      "Epoch 92/100\n",
      "952/952 [==============================] - 9s 9ms/step - loss: 0.1307 - accuracy: 0.9547\n",
      "Epoch 93/100\n",
      "952/952 [==============================] - 9s 9ms/step - loss: 0.1249 - accuracy: 0.9561\n",
      "Epoch 94/100\n",
      "952/952 [==============================] - 9s 9ms/step - loss: 0.1271 - accuracy: 0.9561\n",
      "Epoch 95/100\n",
      "952/952 [==============================] - 9s 9ms/step - loss: 0.1401 - accuracy: 0.9480\n",
      "Epoch 96/100\n",
      "952/952 [==============================] - 9s 9ms/step - loss: 0.1270 - accuracy: 0.9546\n",
      "Epoch 97/100\n",
      "952/952 [==============================] - 9s 9ms/step - loss: 0.1231 - accuracy: 0.9578\n",
      "Epoch 98/100\n",
      "952/952 [==============================] - 9s 9ms/step - loss: 0.1288 - accuracy: 0.9548\n",
      "Epoch 99/100\n",
      "952/952 [==============================] - 9s 9ms/step - loss: 0.1199 - accuracy: 0.9578\n",
      "Epoch 100/100\n",
      "952/952 [==============================] - 9s 9ms/step - loss: 0.1244 - accuracy: 0.9557\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x7fc317fb6ef0>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(input_dim=max_words, output_dim=embedding_dim, input_length=max_sequence_length, weights=[embedding_matrix], trainable=False))\n",
    "model.add(LSTM(8))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "adm = Adam(learning_rate=0.001) \n",
    "model.compile(optimizer=adm, loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "model.fit(padded_sequences_train, targets, epochs=100, batch_size=8)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9f5c4fc2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "102/102 [==============================] - 1s 3ms/step\n"
     ]
    }
   ],
   "source": [
    "pred= model.predict(padded_sequences_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "848f1c07-a57f-4a4b-81ba-c4c19c46a919",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.9951132 ],\n",
       "       [0.9999906 ],\n",
       "       [0.99999976],\n",
       "       ...,\n",
       "       [0.9999987 ],\n",
       "       [0.99107295],\n",
       "       [0.98189455]], dtype=float32)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ad857348-f7ad-44b4-8d5f-c0bd4393e2ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.DataFrame()\n",
    "df[\"id\"]=test_df[\"id\"]\n",
    "pred[pred>0.5] = 1\n",
    "pred[pred<=0.5] = 0\n",
    "df[\"target\"]=pred[:,0]\n",
    "df.to_csv(\"predictions.csv\",index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8602918",
   "metadata": {},
   "source": [
    "### Results\n",
    "Our exploration and subsequent modeling of disaster-related tweets revealed several key insights. Initially, we conducted a comprehensive analysis of both training and test datasets, encompassing 7613 and 3263 tweets, respectively. The training data class distribution showed a relatively balanced scenario with approximately 4300 tweets labeled as non-disaster (class 0) and 3300 as disaster-related (class 1).\n",
    "\n",
    "During the preprocessing phase, we handled missing values in 'keyword' and 'location' columns by substituting them with empty strings, maintaining data integrity. Furthermore, our analysis on tweet lengths highlighted an average tweet length of approximately 101 characters for the training set, indicating a concise nature of the textual data we worked with.\n",
    "\n",
    "The core of our approach involved the application of GloVe embeddings for word representation, chosen for its robustness in capturing word semantics based on their co-occurrence in large text corpora. This facilitated a deeper understanding of the textual nuances present in tweets.\n",
    "\n",
    "Our model architecture combined an embedding layer with LSTM and a dense layer, optimized using Adam with a learning rate of 0.001. This setup aimed to capture both the semantic meaning of words and the sequential nature of text, crucial for understanding the context of tweets accurately.\n",
    "\n",
    "After training over 100 epochs, our model achieved an accuracy of approximately 95.57% on the training set, showcasing its ability to discern between disaster-related and non-disaster-related tweets effectively. The predictions on the test dataset were then compiled into a CSV file, ready for submission or further evaluation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bf135aa",
   "metadata": {},
   "source": [
    "### Conclusion\n",
    "The journey from data exploration to predictive modeling on disaster-related tweets underscored the importance of thorough preprocessing and the power of word embeddings in natural language processing tasks. The GloVe embeddings, in conjunction with LSTM, proved to be effective in capturing the contextual and sequential nuances of textual data, leading to high accuracy in classifying tweets.\n",
    "\n",
    "Despite the challenges posed by missing values and the need for data cleaning, our methodological approach demonstrated that even with relatively simple models, it is possible to achieve significant predictive performance. This suggests a promising avenue for further research and application in real-world scenarios where rapid identification of disaster-related information could be critical.\n",
    "\n",
    "Future work could explore more complex models, incorporate additional data sources, or apply different word embedding techniques to enhance prediction accuracy. Additionally, further tuning of model parameters and exploration of advanced neural network architectures could yield improvements in model performance, providing more nuanced insights into disaster-related communications on social media platforms."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
